import streamlit as st
import pandas as pd
import numpy as np
import math

# --- L0-Flow: –ì–ï–û–ú–ï–¢–†–ò–Ø –ó–û–õ–û–¢–û–ì–û –°–ï–ß–ï–ù–ò–Ø ---
GOLDEN_K = 1.61803398875

def get_coherence_score(signal_slice):
    if len(signal_slice) < 2: return 1.0
    phases = [(v * GOLDEN_K) % 1.0 for v in signal_slice]
    x = np.mean([math.cos(2 * math.pi * p) for p in phases])
    y = np.mean([math.sin(2 * math.pi * p) for p in phases])
    return math.sqrt(x**2 + y**2)

# --- –ò–ù–¢–ï–†–§–ï–ô–° ---
st.set_page_config(page_title="L0-Flow Professional", layout="wide")
st.title("üõ°Ô∏è –ü—Ä–æ—Ç–æ–∫–æ–ª –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: –ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–π –†–µ–∑–æ–Ω–∞–Ω—Å")

uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏ train_FD001.txt", type=['txt'])

if uploaded_file:
    df = pd.read_csv(uploaded_file, sep=r"\s+", header=None)
    engine_id = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏ –ú–æ—Ç–æ—Ä", df[0].unique(), index=0)
    sensor_idx = 11 
    
    engine_data = df[df[0] == engine_id]
    cycles = engine_data[1].values
    raw_values = engine_data[sensor_idx].values
    norm = (raw_values - raw_values.min()) / (raw_values.max() - raw_values.min() + 1e-9)
    
    anomaly_map = []
    log_data = []
    
    # --- –≠–¢–ê–ü 1: –ö–ê–õ–ò–ë–†–û–í–ö–ê (–ü–µ—Ä–≤—ã–µ 30 —Ü–∏–∫–ª–æ–≤ - –æ–±—É—á–µ–Ω–∏–µ) ---
    baseline_scores = []
    for i in range(min(30, len(norm))):
        chunk = norm[max(0, i-5):i+1]
        baseline_scores.append(get_coherence_score(chunk))
    
    avg_baseline = np.mean(baseline_scores) # –£—Ä–æ–≤–µ–Ω—å "–∑–¥–æ—Ä–æ–≤–æ–≥–æ" —à—É–º–∞

    # --- –≠–¢–ê–ü 2: –ê–ù–ê–õ–ò–ó ---
    for i in range(len(norm)):
        chunk = norm[max(0, i-5):i+1]
        score = get_coherence_score(chunk)
        
        # –°—á–∏—Ç–∞–µ–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∏–º–µ–Ω–Ω–æ –æ—Ç –≠–¢–ê–õ–û–ù–ê –∑–¥–æ—Ä–æ–≤—å—è
        # –ï—Å–ª–∏ score —Å—Ç–∞–ª —Å–∏–ª—å–Ω–æ –Ω–∏–∂–µ —ç—Ç–∞–ª–æ–Ω–∞ - —ç—Ç–æ –∏–∑–Ω–æ—Å
        chaos_idx = max(0, (avg_baseline - score) * 100)
        anomaly_map.append(chaos_idx)
        
        # –í —Ç–∞–±–ª–∏—Ü—É –ø–∏—à–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã (–∫–æ–≥–¥–∞ —Ö–∞–æ—Å –≤—ã—à–µ 10%)
        if i > 30 and chaos_idx > 10:
            log_data.append({
                "–¶–∏–∫–ª": int(cycles[i]),
                "–†–µ–∑–æ–Ω–∞–Ω—Å (0-1)": round(score, 3),
                "–ò–Ω–¥–µ–∫—Å –•–∞–æ—Å–∞ (%)": round(chaos_idx, 2),
                "–ü—Ä–æ–≥–Ω–æ–∑": "‚ö†Ô∏è –£–°–¢–ê–õ–û–°–¢–¨" if chaos_idx < 25 else "üõë –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ò–ó–ù–û–°"
            })

    # –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("–õ–∏–Ω–∏—è –¥–∞—Ç—á–∏–∫–∞ (–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ)")
        st.line_chart(raw_values)
    with c2:
        st.subheader("–î–µ—Ç–µ–∫—Ç–æ—Ä –†–∞–∑—Ä—É—à–µ–Ω–∏—è (L0-Flow)")
        st.area_chart(anomaly_map)

    # –û–¢–ß–ï–¢
    st.subheader("üìã –¢–∞–±–ª–∏—Ü–∞ –∞–Ω–æ–º–∞–ª–∏–π (–ø–æ—Å–ª–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏)")
    if log_data:
        report_df = pd.DataFrame(log_data)
        st.dataframe(report_df, use_container_width=True)
        st.download_button("–°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç", report_df.to_csv(index=False).encode('utf-8'), "engine_report_calibrated.csv")
    else:
        st.success("–°–∏—Å—Ç–µ–º–∞ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Ä–µ–∑–æ–Ω–∞–Ω—Å–µ. –ê–Ω–æ–º–∞–ª–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.")

else:
    st.info("–ó–∞–≥—Ä—É–∑–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞.")
